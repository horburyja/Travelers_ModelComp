{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "directory_path = os.path.abspath('/notebooks/')\n",
    "if directory_path not in sys.path:\n",
    "    sys.path.append(directory_path)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "policies_raw = pd.read_csv('../data/policies.csv', index_col=0)\n",
    "cols_to_drop = ['zip', 'county_name', 'Agent_cd']\n",
    "policies_raw = policies_raw.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataValidation:\n",
    "    def __init__(self, df):\n",
    "        self.raw_data = df\n",
    "        self.complete_data = None  # implement this later\n",
    "        self.raw_catvars = self.raw_data.select_dtypes(exclude=[np.number])\n",
    "        self.raw_numvars = self.raw_data.select_dtypes(include=[np.number])\n",
    "\n",
    "    # returns numpy array of categorical variables as they appear in dataset\n",
    "    def get_categoric(self):\n",
    "        return self.raw_catvars.columns.values\n",
    "\n",
    "    # returns numpy array of numerical variables as they appear in dataset\n",
    "    def get_numeric(self):\n",
    "        return self.raw_numvars.columns.values\n",
    "\n",
    "    # returns df of pct missing data points for each predictor\n",
    "    def get_missing(self):\n",
    "        dict_missing = {'col':[], 'pct_missing':[]}\n",
    "\n",
    "        for col in self.raw_data.columns:\n",
    "            mean_missing = np.mean(self.raw_data[col].isnull())\n",
    "            pct_missing = round(mean_missing * 100, 5)\n",
    "            \n",
    "            dict_missing['col'].append(col)\n",
    "            dict_missing['pct_missing'].append(pct_missing)\n",
    "\n",
    "        df_missing = pd.DataFrame(data=dict_missing)\n",
    "        return df_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Quote_dt' 'discount' 'Home_policy_ind' 'state_id' 'quoted_amt'\n",
      " 'Prior_carrier_grp' 'Cov_package_type' 'policy_id' 'split'\n",
      " 'primary_parking']\n",
      "['credit_score' 'CAT_zone' 'number_drivers' 'num_loaned_veh'\n",
      " 'num_owned_veh' 'num_leased_veh' 'total_number_veh' 'convert_ind']\n",
      "                  col  pct_missing\n",
      "0            Quote_dt      0.00000\n",
      "1            discount      0.00000\n",
      "2     Home_policy_ind      0.00000\n",
      "3            state_id      0.00000\n",
      "4          quoted_amt      0.22782\n",
      "5   Prior_carrier_grp     10.17046\n",
      "6        credit_score      0.61023\n",
      "7    Cov_package_type      1.56625\n",
      "8            CAT_zone      0.50852\n",
      "9           policy_id      0.00000\n",
      "10     number_drivers      0.00000\n",
      "11     num_loaned_veh      0.00000\n",
      "12      num_owned_veh      0.00000\n",
      "13     num_leased_veh      0.00000\n",
      "14   total_number_veh      0.00000\n",
      "15        convert_ind     25.00102\n",
      "16              split      0.00000\n",
      "17    primary_parking      0.00000\n"
     ]
    }
   ],
   "source": [
    "policy_data = DataValidation(policies_raw)\n",
    "print(policy_data.get_categoric())\n",
    "print(policy_data.get_numeric())\n",
    "print(policy_data.get_missing())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that there are no duplicate poicy ids before making set of dropped ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_id_counts = policy_data.raw_data['policy_id'].value_counts()\n",
    "duplicates = [item for item in unique_id_counts if item != 1]\n",
    "assert(len(duplicates) == 0) # there are no duplicate ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_policy_ids = set()\n",
    "\n",
    "# make copy of raw policy data df, then drop missing values\n",
    "df_missing_vals = policy_data.raw_data\n",
    "df_missing_vals = df_missing_vals.dropna(how='all').dropna(how='all', axis=1)\n",
    "\n",
    "# store T/F values of isnull() for each policy id in a pd series\n",
    "is_missing = df_missing_vals.isnull().any(axis=1)\n",
    "row_num = 1\n",
    "for item in is_missing:\n",
    "    if item: \n",
    "        dropped_policy_ids.add(policy_data.raw_data['policy_id'][row_num])\n",
    "    row_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that len of dropped policy ids set is equal to total number of rows containing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([False,  True]), array([32176, 16986]))\n"
     ]
    }
   ],
   "source": [
    "is_missing_counts = np.unique(is_missing, return_counts=True)\n",
    "print(is_missing_counts)\n",
    "assert(len(dropped_policy_ids) == is_missing_counts[1][1]) # flagged policy ids were dropped successfully"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
