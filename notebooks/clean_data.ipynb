{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_policies_complete = pd.read_csv('../data/train_policies_complete.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataValidation:\n",
    "    def __init__(self, df):\n",
    "        self._data = df\n",
    "        self.clean = None\n",
    "        self.raw_catvars = self._data.select_dtypes(exclude=[np.number])\n",
    "        self.raw_numvars = self._data.select_dtypes(include=[np.number])\n",
    "\n",
    "    # returns numpy array of categorical variables as they appear in dataset\n",
    "    def get_categoric(self):\n",
    "        return self.raw_catvars.columns.values\n",
    "\n",
    "    # returns numpy array of numerical variables as they appear in dataset\n",
    "    def get_numeric(self):\n",
    "        return self.raw_numvars.columns.values\n",
    "\n",
    "    # returns df of pct missing data points for each predictor\n",
    "    def get_missing(self):\n",
    "        dict_missing = {'col':[], 'pct_missing':[]}\n",
    "\n",
    "        for col in self._data.columns:\n",
    "            mean_missing = np.mean(self._data[col].isnull())\n",
    "            pct_missing = round(mean_missing * 100, 5)\n",
    "            \n",
    "            dict_missing['col'].append(col)\n",
    "            dict_missing['pct_missing'].append(pct_missing)\n",
    "\n",
    "        df_missing = pd.DataFrame(data=dict_missing)\n",
    "        return df_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_policy = DataValidation(train_policies_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAT_zone: [2. 4. 1. 5. 3.]\n",
      "number_drivers: [2 1 4 3 5 6]\n",
      "num_loaned_veh: [1 0 2 3]\n",
      "num_owned_veh: [2 1 3]\n",
      "num_leased_veh: [0 1 2]\n",
      "total_number_veh: [3 4 6 2 5 7 1 8]\n",
      "convert_ind: [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "large = ['credit_score']\n",
    "for col in train_policy.get_numeric():\n",
    "    if col not in large:\n",
    "        print(\"{}: {}\".format(col, train_policy._data[col].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quote_dt: ['2015-01-28' '2018-09-03' '2016-05-18' ... '2017-06-08' '2017-04-27'\n",
      " '2017-10-02']\n",
      "discount: ['Yes' 'No']\n",
      "Home_policy_ind: ['Y' 'N']\n",
      "state_id: ['NY' 'FL' 'MN' 'NJ' 'WI' 'CT' 'GA' 'AL']\n",
      "quoted_amt: ['$5,153' '$3,090' '$14,917' ... '$6,669' '$271' '$8,428']\n",
      "Prior_carrier_grp: ['Carrier_1' 'Carrier_4' 'Carrier_3' 'Carrier_5' 'Carrier_2' 'Carrier_8'\n",
      " 'Carrier_6' 'Carrier_7' 'Other']\n",
      "Cov_package_type: ['High' 'Medium' 'Low']\n",
      "policy_id: ['policy_87209' 'policy_91413' 'policy_71845' ... 'policy_67016'\n",
      " 'policy_30163' 'policy_63982']\n",
      "primary_parking: ['home/driveway' 'unknown' 'parking garage' 'street']\n"
     ]
    }
   ],
   "source": [
    "for col in train_policy.get_categoric():\n",
    "    print(\"{}: {}\".format(col, train_policy._data[col].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2015', '2018', '2016', '2017'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group 'Quote_dt' by year, create dummies\n",
    "train_policy._data['Quote_dt'] = train_policy._data['Quote_dt'].str[:4]\n",
    "train_policy._data['Quote_dt'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = {'midwest':{'WI', 'MN'}, 'southeast':{'FL', 'GA', 'AL'}, 'northeast':{'NY', 'NJ', 'CT'}}\n",
    "for state in train_policy._data['state_id']:\n",
    "    train_policy._data['state_id'][state] = \n",
    "train_policy._data['state_id'] = train_policy._data['state_id'].apply(lambda x: 0 if x == 'No' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex 'quoted_amt' to verify consistent format, convert to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary encode 'discount' and 'Home_poilcy_ind'\n",
    "train_policy._data['discount'] = train_policy._data['discount'].apply(lambda x: 0 if x == 'No' else 1)\n",
    "train_policy._data['Home_policy_ind'] = train_policy._data['Home_policy_ind'].apply(lambda x: 0 if x == 'N' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dummies for 'Quote_dt', 'state_id', 'prior_carrier_group', 'Cov_package_type', 'primary_parking'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "413c54d42d867d78bc5693b88112002b4b75f03abc9fed1665b973f73c05d110"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
