{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "directory_path = os.path.abspath('/notebooks/')\n",
    "if directory_path not in sys.path:\n",
    "    sys.path.append(directory_path)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "policies_raw = pd.read_csv('../data/policies.csv', index_col=0)\n",
    "cols_to_drop = ['zip', 'county_name', 'Agent_cd']\n",
    "policies_raw = policies_raw.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset df according to 'split' variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# subset df according to 'split' variable\n",
    "train_policies_raw = policies_raw[policies_raw['split'] == 'Train']\n",
    "test_policies_raw = policies_raw[policies_raw['split'] == 'Test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataValidation:\n",
    "    def __init__(self, df):\n",
    "        self.raw_data = df\n",
    "        self.complete_data = None  # implement this later\n",
    "        self.raw_catvars = self.raw_data.select_dtypes(exclude=[np.number])\n",
    "        self.raw_numvars = self.raw_data.select_dtypes(include=[np.number])\n",
    "\n",
    "    # returns numpy array of categorical variables as they appear in dataset\n",
    "    def get_categoric(self):\n",
    "        return self.raw_catvars.columns.values\n",
    "\n",
    "    # returns numpy array of numerical variables as they appear in dataset\n",
    "    def get_numeric(self):\n",
    "        return self.raw_numvars.columns.values\n",
    "\n",
    "    # returns df of pct missing data points for each predictor\n",
    "    def get_missing(self):\n",
    "        dict_missing = {'col':[], 'pct_missing':[]}\n",
    "\n",
    "        for col in self.raw_data.columns:\n",
    "            mean_missing = np.mean(self.raw_data[col].isnull())\n",
    "            pct_missing = round(mean_missing * 100, 5)\n",
    "            \n",
    "            dict_missing['col'].append(col)\n",
    "            dict_missing['pct_missing'].append(pct_missing)\n",
    "\n",
    "        df_missing = pd.DataFrame(data=dict_missing)\n",
    "        return df_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_data = DataValidation(policies_raw)\n",
    "# print(policy_data.get_categoric())\n",
    "# print(policy_data.get_numeric())\n",
    "# print(policy_data.get_missing())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that there are no duplicate poicy ids before making set of dropped ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_id_counts = policy_data.raw_data['policy_id'].value_counts()\n",
    "duplicates = [item for item in unique_id_counts if item != 1]\n",
    "assert(len(duplicates) == 0) # there are no duplicate ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_policy_ids = set()\n",
    "\n",
    "# make copy of raw policy data df, then drop missing values\n",
    "df_missing_vals = policy_data.raw_data\n",
    "df_missing_vals = df_missing_vals.dropna(how='all').dropna(how='all', axis=1)\n",
    "\n",
    "# store T/F values of isnull() for each policy id in a pd series\n",
    "is_missing = df_missing_vals.isnull().any(axis=1)\n",
    "for i in range(1, len(is_missing) + 1):\n",
    "    if is_missing[i]:\n",
    "        dropped_policy_ids.add(policy_data.raw_data['policy_id'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that len of dropped policy ids set is equal to total number of rows containing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_missing_counts = np.unique(is_missing, return_counts=True)\n",
    "assert(len(dropped_policy_ids) == is_missing_counts[1][1]) # flagged policy ids were dropped successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote_dt</th>\n",
       "      <th>discount</th>\n",
       "      <th>Home_policy_ind</th>\n",
       "      <th>state_id</th>\n",
       "      <th>quoted_amt</th>\n",
       "      <th>Prior_carrier_grp</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>Cov_package_type</th>\n",
       "      <th>CAT_zone</th>\n",
       "      <th>policy_id</th>\n",
       "      <th>number_drivers</th>\n",
       "      <th>num_loaned_veh</th>\n",
       "      <th>num_owned_veh</th>\n",
       "      <th>num_leased_veh</th>\n",
       "      <th>total_number_veh</th>\n",
       "      <th>convert_ind</th>\n",
       "      <th>split</th>\n",
       "      <th>primary_parking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34089</th>\n",
       "      <td>2015-10-22</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Y</td>\n",
       "      <td>NJ</td>\n",
       "      <td>$2,238</td>\n",
       "      <td>Carrier_5</td>\n",
       "      <td>678.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>policy_43210</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Test</td>\n",
       "      <td>home/driveway</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Quote_dt discount Home_policy_ind state_id quoted_amt  \\\n",
       "34089  2015-10-22      Yes               Y       NJ     $2,238   \n",
       "\n",
       "      Prior_carrier_grp  credit_score Cov_package_type  CAT_zone  \\\n",
       "34089         Carrier_5         678.0              Low       1.0   \n",
       "\n",
       "          policy_id  number_drivers  num_loaned_veh  num_owned_veh  \\\n",
       "34089  policy_43210               5               1              1   \n",
       "\n",
       "       num_leased_veh  total_number_veh  convert_ind split primary_parking  \n",
       "34089               1                 3          NaN  Test   home/driveway  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# policy_43210\n",
    "policy_data.raw_data[policy_data.raw_data['policy_id'] == 'policy_43210']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "413c54d42d867d78bc5693b88112002b4b75f03abc9fed1665b973f73c05d110"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
