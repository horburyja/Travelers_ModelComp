{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_policies_complete = pd.read_csv('../data/train_policies_complete.csv', index_col=0)\n",
    "test_policies_complete = pd.read_csv('../data/test_policies_complete.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleanData:\n",
    "    def __init__(self, df):\n",
    "        self._data = df\n",
    "        self.raw_catvars = self._data.select_dtypes(exclude=[np.number])\n",
    "        self.raw_numvars = self._data.select_dtypes(include=[np.number])\n",
    "    \n",
    "    # returns numpy array of categorical variables as they appear in dataset\n",
    "    def get_categoric(self):\n",
    "        return self.raw_catvars.columns.values\n",
    "\n",
    "    # returns numpy array of numerical variables as they appear in dataset\n",
    "    def get_numeric(self):\n",
    "        return self.raw_numvars.columns.values\n",
    "\n",
    "    def credit_level(self, score):\n",
    "            if score >= 300 and score <= 629:\n",
    "                return 1 # 'Bad'\n",
    "            elif score >= 630 and score <= 689:\n",
    "                return 2 # 'Fair'\n",
    "            elif score >= 690 and score <= 719:\n",
    "                return 3 # 'Good'\n",
    "            else:\n",
    "                return 4 # 'Excellent'\n",
    "\n",
    "    # doesn't really \"clean data\" atm, just groups variables \n",
    "    def clean_data(self):\n",
    "        # group 'credit_score' by rating\n",
    "        self._data['credit_score'] = self._data['credit_score'].apply(self.credit_level)\n",
    "        \n",
    "        # group 'Quote_dt' by year\n",
    "        self._data['Quote_dt'] = self._data['Quote_dt'].str[:4]\n",
    "\n",
    "        # group 'state_id' by region\n",
    "        region = {'WI':'midwest', 'MN':'midwest', 'FL':'southeast', 'GA':'southeast', 'AL':'southeast', \n",
    "                    'NY':'northeast', 'NJ':'northeast', 'CT':'northeast'}\n",
    "        self._data['state_id'] = self._data['state_id'].replace(region)\n",
    "\n",
    "        # regex 'quoted_amt' to float\n",
    "        self._data['quoted_amt'] = self._data['quoted_amt'].replace('[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "        # binary encode 'discount' and 'Home_poilcy_ind'\n",
    "        self._data['discount'] = self._data['discount'].apply(lambda x: 0 if x == 'No' else 1)\n",
    "        self._data['Home_policy_ind'] = self._data['Home_policy_ind'].apply(lambda x: 0 if x == 'N' else 1)\n",
    "\n",
    "        # cast 'Cat_zone' data to int\n",
    "        self._data['CAT_zone'] = self._data['CAT_zone'].astype('int')\n",
    "\n",
    "        # ordinally encode 'Cov_package_type' and 'primary_parking'\n",
    "        cov_map = {'Low':1, 'Medium':2, 'High':3}\n",
    "        park_map = {'home/driveway':1, 'parking garage':2, 'street':3, 'unknown':4}\n",
    "\n",
    "        self._data['Cov_package_type'] = self._data['Cov_package_type'].replace(cov_map)\n",
    "        self._data['primary_parking'] = self._data['primary_parking'].replace(park_map)\n",
    "        self._data['Cov_package_type'] = self._data['Cov_package_type'].astype('int')\n",
    "        self._data['primary_parking'] = self._data['primary_parking'].astype('int')\n",
    "\n",
    "        # set 'policy_id' as row name/index\n",
    "        self._data = self._data.set_index('policy_id')\n",
    "    \n",
    "    def make_dummies(self):\n",
    "        dummy_cols = ['Quote_dt', 'state_id', 'Prior_carrier_grp']\n",
    "        self._data = pd.get_dummies(self._data, columns=dummy_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_policy = CleanData(train_policies_complete)\n",
    "test_policy = CleanData(test_policies_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_policy.clean_data()\n",
    "test_policy.clean_data()\n",
    "train_policy.make_dummies()\n",
    "test_policy.make_dummies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_policy._data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_policy._data.to_csv('../data/train_policies_clean.csv')\n",
    "test_policy._data.to_csv('../data/test_policies_clean.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "413c54d42d867d78bc5693b88112002b4b75f03abc9fed1665b973f73c05d110"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
